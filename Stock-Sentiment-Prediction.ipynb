{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca34d6f-a67f-4fbc-b9c3-8dd521d02db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in e:\\new folder\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in e:\\new folder\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in e:\\new folder\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\new folder\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\new folder\\lib\\site-packages (from nltk>=3.8->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in e:\\new folder\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.4)\n",
      "Requirement already satisfied: colorama in e:\\new folder\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d106183b-958d-4ba0-a234-f6b44f3ab516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: Index(['Unnamed: 0', 'Sentiment', 'Sentence'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\HP\\Downloads\\archive (6)\\Sentiment_Stock_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect column names\n",
    "print(\"Column Names:\", data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c27d0c1-7f4d-4278-9f5a-18a1a4702095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5327356321839081\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.44      0.48     10630\n",
      "           1       0.54      0.62      0.58     11120\n",
      "\n",
      "    accuracy                           0.53     21750\n",
      "   macro avg       0.53      0.53      0.53     21750\n",
      "weighted avg       0.53      0.53      0.53     21750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "# Drop rows with missing values in 'Sentence' and 'Sentiment'\n",
    "data.dropna(subset=['Sentence', 'Sentiment'], inplace=True)\n",
    "\n",
    "# Clean the text data\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove non-alphabetic characters\n",
    "    text = text.lower().strip()  # Convert to lowercase and strip spaces\n",
    "    return text\n",
    "\n",
    "data['Cleaned_Text'] = data['Sentence'].apply(clean_text)\n",
    "\n",
    "# Step 2: Sentiment Analysis (optional, if not already done)\n",
    "# Map Sentiment column to ensure binary labels (0 or 1)\n",
    "data['Sentiment'] = data['Sentiment'].astype(int)\n",
    "# Step 3: Model Development\n",
    "# Feature extraction\n",
    "X = data['Cleaned_Text']\n",
    "y = data['Sentiment']\n",
    "\n",
    "# Convert text to feature vectors using TF-IDF\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_counts = vectorizer.fit_transform(X)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01772a06-8eb6-4772-ba8c-4a5a5ddc3d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:35:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5376091954022989\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.12      0.20     10630\n",
      "           1       0.53      0.93      0.67     11120\n",
      "\n",
      "    accuracy                           0.54     21750\n",
      "   macro avg       0.58      0.53      0.44     21750\n",
      "weighted avg       0.58      0.54      0.44     21750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Predictions and Evaluation\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "655bf9c7-77d8-4d0d-aec9-049eca760765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in e:\\new folder\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in e:\\new folder\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in e:\\new folder\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\new folder\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\new folder\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\new folder\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\new folder\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in e:\\new folder\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in e:\\new folder\\lib\\site-packages (from transformers) (0.20.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\new folder\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\new folder\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\new folder\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\new folder\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in e:\\new folder\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\new folder\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\new folder\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\new folder\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\new folder\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: datasets in e:\\new folder\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in e:\\new folder\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\new folder\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in e:\\new folder\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\new folder\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in e:\\new folder\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\new folder\\lib\\site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in e:\\new folder\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in e:\\new folder\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in e:\\new folder\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in e:\\new folder\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in e:\\new folder\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in e:\\new folder\\lib\\site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in e:\\new folder\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\new folder\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\new folder\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: colorama in e:\\new folder\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\new folder\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\new folder\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\new folder\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\new folder\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Found existing installation: pyarrow 18.1.0\n",
      "Uninstalling pyarrow-18.1.0:\n",
      "  Successfully uninstalled pyarrow-18.1.0\n",
      "Collecting pyarrow\n",
      "  Using cached pyarrow-18.1.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Using cached pyarrow-18.1.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-18.1.0\n",
      "Requirement already satisfied: pandas in e:\\new folder\\lib\\site-packages (2.2.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: datasets in e:\\new folder\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: pyarrow in e:\\new folder\\lib\\site-packages (18.1.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in e:\\new folder\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\new folder\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\new folder\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\new folder\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: filelock in e:\\new folder\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\new folder\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\new folder\\lib\\site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in e:\\new folder\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in e:\\new folder\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in e:\\new folder\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in e:\\new folder\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in e:\\new folder\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in e:\\new folder\\lib\\site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in e:\\new folder\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\new folder\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\new folder\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\new folder\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: colorama in e:\\new folder\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.5 MB 3.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.2/11.5 MB 15.0 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.4/11.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.9/11.5 MB 10.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.0/11.5 MB 9.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.5/11.5 MB 9.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.6/11.5 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.1/11.5 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.4/11.5 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.8/11.5 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.0/11.5 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.2/11.5 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.5/11.5 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.7/11.5 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.8/11.5 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.1/11.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.3/11.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.5/11.5 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.7/11.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.7/11.5 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.0/11.5 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.2/11.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.5/11.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.1/11.5 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.5/11.5 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.8/11.5 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.9/11.5 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.0/11.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.1/11.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.2/11.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.0/11.5 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.5 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.1/11.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.5 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.5 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.1/11.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 5.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "Successfully installed pandas-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip uninstall pyarrow -y\n",
    "!pip install pyarrow --force-reinstall\n",
    "!pip install --upgrade pandas datasets pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da12e166-d55a-4ab1-a9c6-3579b6725508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in e:\\new folder\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in e:\\new folder\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in e:\\new folder\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\new folder\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\new folder\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\new folder\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\new folder\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in e:\\new folder\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in e:\\new folder\\lib\\site-packages (from transformers) (0.20.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\new folder\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\new folder\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\new folder\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\new folder\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in e:\\new folder\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\new folder\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\new folder\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\new folder\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\new folder\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: datasets in e:\\new folder\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in e:\\new folder\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\new folder\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in e:\\new folder\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\new folder\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in e:\\new folder\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\new folder\\lib\\site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in e:\\new folder\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in e:\\new folder\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in e:\\new folder\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in e:\\new folder\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in e:\\new folder\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in e:\\new folder\\lib\\site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in e:\\new folder\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\new folder\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\new folder\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: colorama in e:\\new folder\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\new folder\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\new folder\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\new folder\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\new folder\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Found existing installation: pyarrow 18.1.0\n",
      "Uninstalling pyarrow-18.1.0:\n",
      "  Successfully uninstalled pyarrow-18.1.0\n",
      "Collecting pyarrow\n",
      "  Using cached pyarrow-18.1.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Using cached pyarrow-18.1.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-18.1.0\n",
      "Requirement already satisfied: pandas in e:\\new folder\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: datasets in e:\\new folder\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: pyarrow in e:\\new folder\\lib\\site-packages (18.1.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in e:\\new folder\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\new folder\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\new folder\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\new folder\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: filelock in e:\\new folder\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\new folder\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\new folder\\lib\\site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in e:\\new folder\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in e:\\new folder\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in e:\\new folder\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in e:\\new folder\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in e:\\new folder\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in e:\\new folder\\lib\\site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in e:\\new folder\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\new folder\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\new folder\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\new folder\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\new folder\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\new folder\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: colorama in e:\\new folder\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "The pyarrow installation is not built with support for the Parquet file format (DLL load failed while importing _parquet: The specified procedure could not be found.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install --upgrade pandas datasets pyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpq\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertForSequenceClassification\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer, TrainingArguments\n",
      "File \u001b[1;32mE:\\New folder\\Lib\\site-packages\\pyarrow\\parquet\\__init__.py:20\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Licensed to the Apache Software Foundation (ASF) under one\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# or more contributor license agreements.  See the NOTICE file\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# distributed with this work for additional information\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mE:\\New folder\\Lib\\site-packages\\pyarrow\\parquet\\core.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_parquet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_parquet\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe pyarrow installation is not built with support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the Parquet file format (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(exc)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_parquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ParquetReader, Statistics,  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     41\u001b[0m                               FileMetaData, RowGroupMetaData,\n\u001b[0;32m     42\u001b[0m                               ColumnChunkMetaData,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m                               FileDecryptionProperties,\n\u001b[0;32m     47\u001b[0m                               SortingColumn)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (LocalFileSystem, FileSystem, FileType,\n\u001b[0;32m     49\u001b[0m                         _resolve_filesystem_and_path, _ensure_filesystem)\n",
      "\u001b[1;31mImportError\u001b[0m: The pyarrow installation is not built with support for the Parquet file format (DLL load failed while importing _parquet: The specified procedure could not be found.)"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip uninstall pyarrow -y\n",
    "!pip install pyarrow --force-reinstall\n",
    "!pip install --upgrade pandas datasets pyarrow\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "\n",
    "# Load and preprocess dataset\n",
    "data['label'] = data['Sentiment'].astype(int)\n",
    "dataset = Dataset.from_pandas(data[['Cleaned_Text', 'label']])\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Cleaned_Text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "\n",
    "# Load model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Load accuracy metric\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "# Custom compute_metrics function for accuracy\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), axis=1)\n",
    "    accuracy = metric.compute(predictions=predictions, references=labels)\n",
    "    return accuracy\n",
    "\n",
    "# Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "evaluation_results = trainer.evaluate()\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Evaluation Results:\", evaluation_results)\n",
    "print(\"Accuracy:\", evaluation_results['eval_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f02b1-9098-4479-a17a-18c0483d0233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
